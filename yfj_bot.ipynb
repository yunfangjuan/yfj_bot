{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install necessary the library below \n",
    "# Run this notebook with python-3.10 or up\n",
    "#!pip3 install bs4\n",
    "!pip3 install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "OPEN_AI_API_KEY = '<YOUR_OPEN_AI_KEY>'\n",
    "openai.api_key = OPEN_AI_API_KEY \n",
    "\n",
    "def ask_davinci(question):\n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=question,\n",
    "      temperature=0.1,\n",
    "      max_tokens=2000, \n",
    "      n=1\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "def ask_gpt3(question):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    )\n",
    "    return completion.choices[0].message.content #.strip()\n",
    "\n",
    "def ask_character(post_list, question):\n",
    "    prompt = [\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an assistant answering questions based on what the writer YFJ wrote\"\n",
    "        }, \n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Here are some articles the writer YFJ wrote:\"\n",
    "        }]\n",
    "   \n",
    "    for post in post_list:\n",
    "        prompt.append({\"role\": \"user\", \"content\": f\"\"\"{post['title']}: {post['content']} \"\"\"})\n",
    "    \n",
    "    prompt.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"The writer YFJ was asked the question after the delimiter =====. Please answer the question as if you are the writer YFJ. Start the answer with the word I. Say I don't know or I don't have an opinion if there's no relevant writing from the writer.  ===== {question}\"\n",
    "        })\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model= \"gpt-3.5-turbo\",\n",
    "        messages=prompt\n",
    "    )\n",
    "    return completion.choices[0].message.content #.strip()\n",
    "\n",
    "def get_embedding(input): \n",
    "    embedding = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=input\n",
    "    )\n",
    "    return embedding.data[0].embedding\n",
    "\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Compute the dot product of vec1 and vec2\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "\n",
    "    # Compute the L2 norms (Euclidean norms) of vec1 and vec2\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "\n",
    "    # Compute the cosine similarity\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "with open('greatreset-embeddings.json', 'r') as infile:\n",
    "    # Write the JSON data to the file\n",
    "    embedding_tuples = json.load(infile) \n",
    "\n",
    "print(len(embedding_tuples))\n",
    "with open('greatreset.json', 'r') as infile2:\n",
    "    # Write the JSON data to the file\n",
    "    post_list = json.load(infile2) \n",
    "print(len(post_list))\n",
    "\n",
    "post2content = {}\n",
    "for post in post_list: \n",
    "    post2content[post['post_id']] = post \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Q: Do you think the Fed will lower interest rates in 2023?\n",
      "YFJ Bot: I personally don't think the Fed will lower interest rates in 2023 unless there is another COVID-19 kind of disaster. The upward pressure of food, labor, and potentially energy prices will likely keep interest rates elevated. Based on the FOMC members' projections, the rates will continue to rise and reach around 5%, which means we will see risk-free investments yielding close to 5% in 2023. Unless the inflation rate significantly decreases or the economy experiences an unexpected downturn, I believe the Fed will keep or even raise interest rates to maintain price stability.\n"
     ]
    }
   ],
   "source": [
    "N=10 # change this number to a smaller number if you got an error for token limit overflow\n",
    "#question = \"What do you think of Tesla's stock price?\" \n",
    "#question = \"What do you think of Meta's Metaverse?\"\n",
    "#question = \"Do you think the Fed does a good job?\"\n",
    "#question = \"What are your stock picks for 2023?\"\n",
    "#question = \"Do you think there will be another great depression?\"\n",
    "#question = \"Will there be IPOs in 2023?\"\n",
    "#question = \"What will happen to venture capital in 2023?\"\n",
    "question = \"Do you think the Fed will lower interest rates in 2023?\"\n",
    "emq = get_embedding(question) \n",
    "\n",
    "scores = []\n",
    "post_ids = []\n",
    "for et in  embedding_tuples: \n",
    "    post_ids.append(et[1])\n",
    "    scores.append(cosine_similarity(emq, et[0]))\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "\n",
    "\n",
    "scores_array = np.array(scores)\n",
    "\n",
    "# Get the indices that would sort the array\n",
    "sorted_indices = np.argsort(scores_array)\n",
    "\n",
    "# Get the top N indices. Note: [::-1] is used to reverse the array because argsort sorts in ascending order\n",
    "top_N_indices = sorted_indices[-N:]\n",
    "scores_array[top_N_indices]\n",
    "\n",
    "#print(top_N_indices)\n",
    "#print(scores_array[top_N_indices])\n",
    "\n",
    "relevant_posts = list(set(np.array(post_ids)[top_N_indices]))\n",
    "#print(relevant_posts)\n",
    "\n",
    "input_list = []\n",
    "for p in relevant_posts: \n",
    "    input_list.append(post2content[p])\n",
    "result = ask_character(input_list, question)\n",
    "print(\"============================\")\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"YFJ Bot: {result}\") \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
